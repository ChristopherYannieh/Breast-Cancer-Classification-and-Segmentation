# -*- coding: utf-8 -*-
"""MaskRCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tDgd-bAUvnLBnYwYkm3uzyWAzi2_UmFt

# Mask RCNN
"""

# Mount drive
from google.colab import drive
drive.mount('/content/drive')

"""## Import Libraries"""

from IPython.display import clear_output

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/ZAKA AI/Artificial Intelligence Program/Capstone Project/Mask-RCNN-TF2/mrcnn

!pip uninstall keras -y
!pip uninstall keras-nightly -y
!pip uninstall keras-Preprocessing -y
!pip uninstall keras-vis -y
!pip uninstall tensorflow -y
!pip uninstall h5py -y
clear_output()

!pip install tensorflow==1.13.1
!pip install keras==2.0.8
!pip install h5py==2.10.0
clear_output()

!pip uninstall scikit-image
!pip install scikit-image==0.16.2
clear_output()

import warnings
warnings.filterwarnings('ignore')

import os
import sys
import json
import datetime
import numpy as np
import skimage.draw

from matplotlib import pyplot as plt
from visualize import display_instances, display_top_masks
from utils import extract_bboxes
from utils import Dataset
from config import Config
from model import MaskRCNN
import model as modellib, utils
from PIL import Image, ImageDraw

"""## Create Dataset Class"""

class BreastUltrasoundImagesDataset(utils.Dataset):
    def load_data(self, annotation_json, images_dir):
        """ Load the dataset from json
        Args:
            annotation_json: The path to the coco annotations json file
            images_dir: The directory holding the images referred to by the json file
        """
        # Load json from file
        json_file = open(annotation_json)
        coco_json = json.load(json_file)
        json_file.close()
        
        # Add the class names using the base method from utils.Dataset
        source_name = "coco_like"
        for category in coco_json['categories']:
            class_id = category['id']
            class_name = category['name']
            
            self.add_class(source_name, class_id, class_name)
        
        # Get all annotations
        annotations = {}
        for annotation in coco_json['annotations']:
            image_id = annotation['image_id']
            if image_id not in annotations:
                annotations[image_id] = []
            annotations[image_id].append(annotation)
        
        
        # Get all images and add them to the dataset
        seen_images = {}
        for image in coco_json['images']:
            image_id = image['id']
            if image_id in seen_images:
                print("Warning: Skipping duplicate image id: {}".format(image))
            else:
                seen_images[image_id] = image
                try:
                    image_file_name = image['file_name']
                    image_width = image['width']
                    image_height = image['height']
                except KeyError as key:
                    print("Warning: Skipping image (id: {}) with missing key: {}".format(image_id, key))
                
                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))
                image_annotations = annotations[image_id]

                # Add the image using the base method from utils.Dataset
                self.add_image(
                    source=source_name,
                    image_id=image_id,
                    path=image_path,
                    width=image_width,
                    height=image_height,
                    annotations=image_annotations
                )
      
    def load_mask(self, image_id):
        """ Load instance masks for the given image.
        MaskRCNN expects masks in the form of a bitmap [height, width, instances].
        Args:
            image_id: The id of the image to load masks for
        Returns:
            masks: A bool array of shape [height, width, instance count] with
                one mask per instance.
            class_ids: a 1D array of class IDs of the instance masks.
        """
        image_info = self.image_info[image_id]
        annotations = image_info['annotations']
        instance_masks = []
        class_ids = []
        
        for annotation in annotations:
            class_id = annotation['category_id']
            mask = Image.new('1', (image_info['width'], image_info['height']))
            mask_draw = ImageDraw.ImageDraw(mask, '1')
            for segmentation in annotation['segmentation']:
                mask_draw.polygon(segmentation, fill=1)
                bool_array = np.array(mask) > 0
                instance_masks.append(bool_array)
                class_ids.append(class_id)

        mask = np.dstack(instance_masks)
        class_ids = np.array(class_ids, dtype=np.int32)
        
        return mask, class_ids

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/ZAKA AI/Artificial Intelligence Program/Capstone Project/Mask-RCNN-TF2/custom_Mask_RCNN/Breast-Ultrasound-Images

dataset_train = BreastUltrasoundImagesDataset()
dataset_train.load_data('train/train_labels.json', images_dir = 'train/')
dataset_train.prepare()

dataset_val = BreastUltrasoundImagesDataset()
dataset_val.load_data('val/val_labels.json', images_dir = 'val/')
dataset_val.prepare()

"""## Inspect the Dataset"""

dataset = dataset_train
image_ids = dataset.image_ids

# Select 3 random images
image_ids = np.random.choice(dataset.image_ids, 3)
for image_id in image_ids:
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    display_top_masks(image, mask, class_ids, dataset.class_names, limit=1)

# Load an image from Dataset
image_id = 0
image = dataset_train.load_image(image_id)

# Load the Masks and the Class IDs
mask, class_ids = dataset_train.load_mask(image_id)

# Extract Bounding Boxes from the Masks
bbox = extract_bboxes(mask)

# Display Image with Masks and Bounding Boxes
display_instances(image, bbox, mask, class_ids, dataset_train.class_names)

"""## Create Configuration Class"""

# Define a configuration for the model
class BreastUltrasoundImagesDatasetConfig(Config):
	# Name of the configuration
	NAME = "breast_ultrasound_images_config"
	# number of classes (Background + (Benign + Malignant))
	NUM_CLASSES = 1+2
	# Number of training steps per epoch
	STEPS_PER_EPOCH = 50
  #DETECTION_MIN_CONFIDENCE = 0.9 # Skip detections with < 90% confidence
	IMAGE_PER_GPU = 1


# prepare config
config = BreastUltrasoundImagesDatasetConfig()
config.display()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Capstone Project

"""## Mask RCNN Model with COCO Weights"""

ROOT_DIR = os.path.abspath("./")

# Import Mask RCNN
sys.path.append(ROOT_DIR)  # To find local version of the library
# Directory to save logs and trained model
DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, "logs")
# Path to trained weights file
COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, "coco-weights/mask_rcnn_coco.h5")

# Define the model
model = MaskRCNN(mode='training', model_dir=DEFAULT_LOGS_DIR, config=config)

# Load weights (mscoco) and exclude the output layers
model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])

model.load_weights("MASK_RCNN.h5", by_name = True)

"""## Training"""

# Train model (output layers or 'heads')
model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads')

"""## Save Model"""

model.save('MASK_RCNN.h5')